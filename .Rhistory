head(trd)
tsd
head(herod,1)
head(herod)
trhrd <- herod %>%
select(hero_id, roles) %>%
mutate(role = str_split(roles,":")) %>%
select(hero_id,role) %>%
unnest() %>%
spread(role,role)
tr9d
#################Part-1 : install and load all the required packages#################
#Creating vector with all required packages
required_packages <- c("caret", "Metrics","dplyr","tidyr","stringr","rpart","ipred","randomForest","gbm","e1071", "dummies", "Boruta")
#Load all the required packages for this project
for(i in 1:length(required_packages )){
library(required_packages[i], character.only = T)
}
setwd("E:\\Data Science\\Competitions\\Analytic Vidhya\\3 Kings of Machine Learning")
train9d <- read.csv(file.choose()) #Train 9 data
train1d <- read.csv(file.choose()) #Train 1 data
test9d <- read.csv(file.choose()) #Test 9 data
test1d <- read.csv(file.choose()) #Test 1 data
herod <- read.csv(file.choose()) #Heroes data
#Common id column does not provide any useful information which can be used in model building
#num_wins column also not important
#Delete common id and num_wins columns from both train and test data as they are not important
train9d <- train9d[,-c(3,5)]
train1d <- train1d[,-c(3,5)]
test9d <- test9d[,-c(3,5)]
test1d <- test1d[,-c(3,5)]
str(train9d)
str(train1d)
str(test9d)
str(test1d)
str(herod)
#Transform hero data. Here, creating dummy variables for hero roles as they can be used in model building
trhrd <- herod %>% #Pipe hero data to dplyr's select function and selecting hero_id and roles column
select(hero_id, roles) %>%
mutate(role = str_split(roles,":")) %>% #Creating new column and separate roles in nest format
select(hero_id,role) %>%
unnest() %>% #Unnest all the roles
spread(role,role) #Tidying. Creating new column for every role by specifying role as both column and key
trhrd[is.na(trhrd)] <- 0 #The above resulted data.frame contains NAs because certain heroes do not have certain roles. Simply put 0 where is a value as NA
trhrd[trhrd != 0] <- 1 #Put 1, if the hero plays the role
trhrd <- sapply(trhrd,as.integer) #Convert all the rows as integers
hero_roles  <- as.data.frame(trhrd)
hero_roles$hero_id <- herod$hero_id #Re-assign the hero_id column
hero_stat <- herod[,-c(4,5,7,8,10,21)] #Removing zero variance columns from hero data
hero_stat$attack_type <- ifelse(hero_stat$attack_type == "Melee",1,0)
hero_stat <- cbind(hero_stat,dummy(hero_stat$primary_attr, sep = "_")) #Here, dummy function from dummies package creates dummy variables
hero_stat <- hero_stat[,-c(2, ncol(hero_stat))] #Deleting this column because already created dummy variables with this column levels
hero_all_trsf <- left_join(hero_roles, hero_stat, by = "hero_id")
tr9d_all <- left_join(train9d, hero_all_trsf, by = "hero_id")
tr1d_all <- left_join(train1d, hero_all_trsf, by = "hero_id")
ts9d_all <- left_join(test9d, hero_all_trsf, by = "hero_id")
ts1d_all <- left_join(test1d, hero_all_trsf, by = "hero_id")
#user_id and hero_id columns are contains with integer data. But should be in factor format.
#Converting both user_id and hero_id columns into factor format
tr9d_all$user_id <- as.factor(tr9d_all$user_id)
tr1d_all$user_id <- as.factor(tr1d_all$user_id)
tr9d_all$hero_id <- as.factor(tr9d_all$hero_id)
tr1d_all$hero_id <- as.factor(tr1d_all$hero_id)
ts9d_all$user_id <- as.factor(ts9d_all$user_id)
ts1d_all$user_id <- as.factor(ts1d_all$user_id)
ts9d_all$hero_id <- as.factor(ts9d_all$hero_id)
ts1d_all$hero_id <- as.factor(ts1d_all$hero_id)
str(tr9d_all)
str(tr1d_all)
str(ts9d_all)
str(ts1d_all)
selected <- levels(tr9d_all$user_id)[1:1023]
head(selected)
t9 <- tr9d_all[tr9d_all$user_id %in% selected,]
str(t9)
t9$user_id <- factor(t9$user_id)
str(t9)
t1 <- tr1d_all[tr1d_all$user_id %in% selected,]
t1$user_id <- factor(t1$user_id)
###########
model <- randomForest(formula = kda_ratio ~ .,
data = t9[,-c(1,2)]
)
mode()
model
names(model)
model(mse)
model$mse
names(model)
model(importance())
model$importance
names(model)
model$oob.times
model$importanceSD
names(model)
boruta_model <- Boruta(kda_ratio ~ ., data = t9, doTrace = 2)
boruta_model
#######################
gbm_model <- gbm(formula = kda_ratio ~ .,
distribution = "gaussian",
data = t9,
n.trees = 50,
cv.folds = 5)
# Optimal ntree estimate based on CV
ntree_opt_cv <- gbm.perf(object = gbm_model,
method = "cv")
print(paste0("Optimal n.trees (CV Estimate): ", ntree_opt_cv))
# Generate predictions on the test set using ntree_opt_cv number of trees
gbm_predictions <- predict(object = gbm_model,
newdata = t1,
n.trees = ntree_opt_cv)
write.csv(gbm_predictions, "gbm_predictions.csv")
Generate the test set rmse
#Generate the test set rmse
gbm_rmse <- rmse(actual = t1$, gbm_pred = gbm_predictions)
#Generate the test set rmse
gbm_rmse <- rmse(actual = t1$kda_ratio, gbm_pred = gbm_predictions)
#Generate the test set rmse
gbm_rmse <- rmse(actual = t1$kda_ratio, gbm_predictions)
gbm_rmse
str(t9)
t9$num_games <- NULL
str(t9)
#######################
gbm_model <- gbm(formula = kda_ratio ~ .,
distribution = "gaussian",
data = t9,
n.trees = 50,
cv.folds = 5)
# Optimal ntree estimate based on CV
ntree_opt_cv <- gbm.perf(object = gbm_model,
method = "cv")
print(paste0("Optimal n.trees (CV Estimate): ", ntree_opt_cv))
# Generate predictions on the test set using ntree_opt_cv number of trees
gbm_predictions <- predict(object = gbm_model,
newdata = t1,
n.trees = ntree_opt_cv)
write.csv(gbm_predictions, "gbm_predictions.csv")
#Generate the test set rmse
gbm_rmse <- rmse(actual = t1$kda_ratio, gbm_predictions)
gbm_rmse
control <- trainControl(method="repeatedcv", number=10)
# train the model
model <- train(kda_ratio~., data=t9[,-c(1,2)], method="lm", preProcess="scale", trControl=control)
# estimate variable importance
importance <- varImp(model, scale=FALSE)
# summarize importance
print(importance)
# plot importance
plot(importance)
names(importance)
importance$importance
importance$model
importance$calledFrom
# train the model
model2 <- train(kda_ratio~., data=t9[,-c(1,2)], method="ranger", preProcess="scale", trControl=control)
control <- trainControl(method="repeatedcv", number=2)
# train the model
model2 <- train(kda_ratio~., data=t9[,-c(1,2)], method="ranger", preProcess="scale", trControl=control)
# estimate variable importance
importance2 <- varImp(model2, scale=FALSE)
# summarize importance
print(importance)
# summarize importance
print(importance2)
control <- trainControl(method="repeatedcv", number=5, verboseIter = TRUE)
# train the model
model2 <- train(kda_ratio~., data=t9[,-c(1,2)], method="ranger", preProcess="scale", trControl=control)
# estimate variable importance
importance2 <- varImp(model2, scale=FALSE)
# summarize importance
print(importance)
importance
importance$importance
a <- importance$importance
a
length(a)
dims(a)
str(t9)
predictors(importance)
predictors(importance$importance)
str(t9)
##################
# define the control using a random forest selection function
control <- rfeControl(functions=rfFuncs, method="cv", number=2, verbose = TRUE)
# run the RFE algorithm
results <- rfe(t9[,-c(1,2,3)], t9d[,3], sizes=c(1:25), rfeControl=control)
# run the RFE algorithm
results <- rfe(t9[,-c(1,2,3)], t9[,3], sizes=c(1:25), rfeControl=control)
# summarize the results
print(results)
##################
# define the control using a random forest selection function
control <- rfeControl(functions=rfFuncs, method="cv", number=, verbose = TRUE)
##################
# define the control using a random forest selection function
control <- rfeControl(functions=rfFuncs, method="cv", number=1, verbose = TRUE)
# run the RFE algorithm
results <- rfe(t9[,-c(1,2,3)], t9[,3], sizes=c(1:25), rfeControl=control)
dim(t9)
##################
# define the control using a random forest selection function
control <- rfeControl(functions=rfFuncs, method="cv", number=1, verbose = TRUE)
# run the RFE algorithm
results <- rfe(t9[,-c(1,2,3)], t9[,3], sizes=c(1:25), rfeControl=control)
str(tr9d_all)
train9d <- read.csv(file.choose()) #Train 9 data
train1d <- read.csv(file.choose()) #Train 1 data
test9d <- read.csv(file.choose()) #Test 9 data
test1d <- read.csv(file.choose()) #Test 1 data
herod <- read.csv(file.choose()) #Heroes data
#Common id column does not provide any useful information which can be used in model building
#num_wins column also not important
#Delete common id and num_wins columns from both train and test data as they are not important
train9d <- train9d[,-c(3,5)]
train1d <- train1d[,-c(3,5)]
test9d <- test9d[,-c(3,5)]
test1d <- test1d[,-c(3,5)]
str(train9d)
str(train1d)
str(test9d)
str(test1d)
str(herod)
train9d <- read.csv(file.choose()) #Train 9 data
train1d <- read.csv(file.choose()) #Train 1 data
test9d <- read.csv(file.choose()) #Test 9 data
test1d <- read.csv(file.choose()) #Test 1 data
str(train9d)
#Common id column does not provide any useful information which can be used in model building
#num_wins column also not important
#Delete common id and num_wins columns from both train and test data as they are not important
train9d <- train9d[,-c(3,4,5)]
train1d <- train1d[,-c(3,4,5)]
test9d <- test9d[,-c(3,4,5)]
test1d <- test1d[,-c(3,4,5)]
str(train9d)
str(train1d)
str(test9d)
str(test1d)
str(herod)
#Transform hero data. Here, creating dummy variables for hero roles as they can be used in model building
trhrd <- herod %>% #Pipe hero data to dplyr's select function and selecting hero_id and roles column
select(hero_id, roles) %>%
mutate(role = str_split(roles,":")) %>% #Creating new column and separate roles in nest format
select(hero_id,role) %>%
unnest() %>% #Unnest all the roles
spread(role,role) #Tidying. Creating new column for every role by specifying role as both column and key
trhrd[is.na(trhrd)] <- 0 #The above resulted data.frame contains NAs because certain heroes do not have certain roles. Simply put 0 where is a value as NA
trhrd[trhrd != 0] <- 1 #Put 1, if the hero plays the role
trhrd <- sapply(trhrd,as.integer) #Convert all the rows as integers
hero_roles  <- as.data.frame(trhrd)
hero_roles$hero_id <- herod$hero_id #Re-assign the hero_id column
hero_stat <- herod[,-c(4,5,7,8,10,21)] #Removing zero variance columns from hero data
hero_stat$attack_type <- ifelse(hero_stat$attack_type == "Melee",1,0)
hero_stat <- cbind(hero_stat,dummy(hero_stat$primary_attr, sep = "_")) #Here, dummy function from dummies package creates dummy variables
hero_stat <- hero_stat[,-c(2, ncol(hero_stat))] #Deleting this column because already created dummy variables with this column levels
hero_all_trsf <- left_join(hero_roles, hero_stat, by = "hero_id")
tr9d_all <- left_join(train9d, hero_all_trsf, by = "hero_id")
tr1d_all <- left_join(train1d, hero_all_trsf, by = "hero_id")
ts9d_all <- left_join(test9d, hero_all_trsf, by = "hero_id")
ts1d_all <- left_join(test1d, hero_all_trsf, by = "hero_id")
#user_id and hero_id columns are contains with integer data. But should be in factor format.
#Converting both user_id and hero_id columns into factor format
tr9d_all$user_id <- as.factor(tr9d_all$user_id)
tr1d_all$user_id <- as.factor(tr1d_all$user_id)
tr9d_all$hero_id <- as.factor(tr9d_all$hero_id)
tr1d_all$hero_id <- as.factor(tr1d_all$hero_id)
ts9d_all$user_id <- as.factor(ts9d_all$user_id)
ts1d_all$user_id <- as.factor(ts1d_all$user_id)
ts9d_all$hero_id <- as.factor(ts9d_all$hero_id)
ts1d_all$hero_id <- as.factor(ts1d_all$hero_id)
str(tr9d_all)
str(tr1d_all)
str(ts9d_all)
str(ts1d_all)
################################ Tuning of GBM for best model################################
set.seed(1)
gbm_model <- gbm(formula = kda_ratio ~ .,
distribution = "gaussian",
data = ts9d_all,
n.trees = 8000,
cv.folds = 5)
# Optimal ntree estimate based on CV
ntree_opt_cv <- gbm.perf(object = gbm_model,
method = "cv")
print(paste0("Optimal n.trees (CV Estimate): ", ntree_opt_cv))
# Generate predictions on the test set using ntree_opt_cv number of trees
gbm_predictions <- predict(object = gbm_model,
newdata = ts1d_all,
n.trees = ntree_opt_cv)
write.csv(gbm_predictions, "gbm_predictions.csv")
################################
a <- c("Nuker","Pusher","Initiator","Durable","projectile_speed","agility_gain","base_attack_max","Jungler","strength_gain","base_health_regen")
a
gbm_model <- gbm(formula = kda_ratio ~ .,
distribution = "gaussian",
data = ts9d_all[,-a],
n.trees = 8000,
cv.folds = 5)
gbm_model <- gbm(formula = kda_ratio ~ .,
distribution = "gaussian",
data = ts9d_all[,-c(a)],
n.trees = 8000,
cv.folds = 5)
#@@@@@@@@@@@@@
ts9d_all <- ts9d_all[,-a]
#@@@@@@@@@@@@@
ts9d_all <- ts9d_all[,-c("Nuker","Pusher","Initiator","Durable","projectile_speed","agility_gain","base_attack_max","Jungler","strength_gain","base_health_regen")]
gbm_model <- gbm(formula = kda_ratio ~ .,
distribution = "gaussian",
data = ts9d_all,
n.trees = 10000,
cv.folds = 5)
# Optimal ntree estimate based on CV
ntree_opt_cv <- gbm.perf(object = gbm_model,
method = "cv")
print(paste0("Optimal n.trees (CV Estimate): ", ntree_opt_cv))
# Generate predictions on the test set using ntree_opt_cv number of trees
gbm_predictions <- predict(object = gbm_model,
newdata = ts1d_all,
n.trees = ntree_opt_cv)
write.csv(gbm_predictions_final, "gbm_predictions2.csv")
write.csv(gbm_predictions, "gbm_predictions2.csv")
required_packages <- c("caret", "Metrics","dplyr","tidyr","stringr","rpart","ipred","randomForest","gbm","e1071", "dummies")
not_installed_packages <- required_packages[!required_packages %in% installed.packages()[,"Package"]]
if(length(not_installed_packages) == 0){
"All required packages are installed"
} else {
for(i in 1:length(not_installed_packages)){
install.packages(not_installed_packages[i])
}
}
for(i in 1:length(required_packages )){
library(required_packages[i], character.only = T)
}
setwd("E:\\1 Data Science\\Competitions\\Analytic Vidhya\\3 Kings of Machine Learning")
####################################################
train9d <- read.csv(file.choose()) #Read train data
test9d <- read.csv(file.choose()) #Read test data
train1d <- read.csv(file.choose())
test1d <- read.csv(file.choose())
herod <- read.csv(file.choose()) #Read hero data
head(train9d)
tr9d <- train9d[,-c(3,5)] #Delete common id and num_wins columns from train data
ts9d <- test9d[,-c(3,5)] #Delete common id and num_wins columns from test data
ts1d <- test1d[,-c(3,5)]
tr1d <- train1d[,-c(3,5)]
#Transform hero data. Here, creating dummy variables for hero roles as they can be used in model building
trhrd <- herod %>%
select(hero_id, roles) %>%
mutate(role = str_split(roles,":")) %>%
select(hero_id,role) %>%
unnest() %>%
spread(role,role)
head(trhrd)
trhrd[is.na(trhrd)] <- 0
trhrd[trhrd != 0] <- 1
trhrd$hero_id <- herod$hero_id
typeof(trhrd)
class(trhrd)
trhrd <- sapply(trhrd,as.integer)
str(herod)
herod %>%
select(hero_id, roles)
herod %>%
select(hero_id, roles) %>%
mutate(role = str_split(roles,":"))
herod %>%
select(hero_id, roles) %>%
mutate(role = str_split(roles,":")) %>%
select(hero_id,role) %>%
unnest()
herod %>%
select(hero_id, roles) %>%
mutate(role = str_split(roles,":")) %>%
select(hero_id,role) %>%
unnest() %>%
spread(role,role)
#Transform hero data. Here, creating dummy variables for hero roles as they can be used in model building
trhrd <- herod %>%
select(hero_id, roles) %>%
mutate(role = str_split(roles,":")) %>%
select(hero_id,role) %>%
unnest() %>%
spread(role,role)
trhrd[is.na(trhrd)] <- 0
trhrd[trhrd != 0] <- 1
trhrd$hero_id <- herod$hero_id
trhrd <- sapply(trhrd,as.integer)
atkr_type  <- as.data.frame(trhrd)
hero_stat <- herod[,-c(4,5,7,8,10,21)]
hero_stat$attack_type <- ifelse(hero_stat$attack_type == "Melee",1,0)
dummy(hero_stat$primary_attr, sep = "_")
hero_stat <- cbind(hero_stat,dummy(hero_stat$primary_attr, sep = "_")) #Here, dummy function from dummies package creates dummy variables
head(hero_stat,2)
hero_stat <- hero_stat[,-c(2, ncol(hero_stat))] #Deleting this column because already created dummy variables with this column levels
hero_all_trsf <- left_join(atkr_type, hero_stat, by = "hero_id")
###################################################
tr9d_atkr_type <- left_join(tr9d,atkr_type, by = "hero_id")
tr9d_hero_stat <-  left_join(tr9d,hero_stat, by = "hero_id")
tr9d_all <- left_join(tr9d, hero_all_trsf, by = "hero_id")
ts9d_atkr_type <- left_join(ts9d,atkr_type, by = "hero_id")
ts9d_hero_stat <-  left_join(ts9d,hero_stat, by = "hero_id")
ts9d_all <- left_join(ts9d, hero_all_trsf, by = "hero_id")
features_type <- c("user_id*hero_id",colnames(tr9d_atkr_type)[-c(1,2,4)])
features_stat <- c("user_id*hero_id",colnames(tr9d_hero_stat)[-c(1,2,4)])
features_all <- c("user_id*hero_id",colnames(tr9d_all)[-c(1,2,4)])
formula_type <- as.formula(paste("kda_ratio~ ", paste(features_type, collapse= "+")))
formula_stat <- as.formula(paste("kda_ratio~ ", paste(features_stat, collapse= "+")))
formula_all <- as.formula(paste("kda_ratio~ ", paste(features_all, collapse= "+")))
#@@@@@@@@@@@@@@@@@
trdwf <- tr9d_all
tsdwf <- ts9d_all
trdwf$user_id <- as.factor(trdwf$user_id)
trdwf$hero_id <- as.factor(trdwf$hero_id)
tsdwf$user_id <- as.factor(tsdwf$user_id)
tsdwf$hero_id <- as.factor(tsdwf$hero_id)
#################################
model <- lm(kda_ratio ~ ., trdwf)
pred <- predict(model, tsdwf[-1])
pred <- predict(model, tsdwf)
head(tsdwf)
str(tsdwf)
str(trdwf)
pred <- predict(model, tsdwf)
head(tsdwf)
head(trdwf)
tsdwf <- tr1d_all
pred <- predict(model, tsdwf)
#Common id column does not provide any useful information which can be used in model building
#num_wins column also not important
#Delete common id and num_wins columns from both train and test data as they are not important
train9d <- train9d[,-c(3,4,5)]
train1d <- train1d[,-c(3,4,5)]
test9d <- test9d[,-c(3,4,5)]
test1d <- test1d[,-c(3,4,5)]
str(train9d)
str(train1d)
str(test9d)
str(test1d)
str(herod)
#Transform hero data. Here, creating dummy variables for hero roles as they can be used in model building
trhrd <- herod %>% #Pipe hero data to dplyr's select function and selecting hero_id and roles column
select(hero_id, roles) %>%
mutate(role = str_split(roles,":")) %>% #Creating new column and separate roles in nest format
select(hero_id,role) %>%
unnest() %>% #Unnest all the roles
spread(role,role) #Tidying. Creating new column for every role by specifying role as both column and key
trhrd[is.na(trhrd)] <- 0 #The above resulted data.frame contains NAs because certain heroes do not have certain roles. Simply put 0 where is a value as NA
trhrd[trhrd != 0] <- 1 #Put 1, if the hero plays the role
trhrd <- sapply(trhrd,as.integer) #Convert all the rows as integers
hero_roles  <- as.data.frame(trhrd)
hero_roles$hero_id <- herod$hero_id #Re-assign the hero_id column
hero_stat <- herod[,-c(4,5,7,8,10,21)] #Removing zero variance columns from hero data
hero_stat$attack_type <- ifelse(hero_stat$attack_type == "Melee",1,0)
hero_stat <- cbind(hero_stat,dummy(hero_stat$primary_attr, sep = "_")) #Here, dummy function from dummies package creates dummy variables
hero_stat <- hero_stat[,-c(2, ncol(hero_stat))] #Deleting this column because already created dummy variables with this column levels
hero_all_trsf <- left_join(hero_roles, hero_stat, by = "hero_id")
tr9d_all <- left_join(train9d, hero_all_trsf, by = "hero_id")
tr1d_all <- left_join(train1d, hero_all_trsf, by = "hero_id")
ts9d_all <- left_join(test9d, hero_all_trsf, by = "hero_id")
ts1d_all <- left_join(test1d, hero_all_trsf, by = "hero_id")
#user_id and hero_id columns are contains with integer data. But should be in factor format.
#Converting both user_id and hero_id columns into factor format
tr9d_all$user_id <- as.factor(tr9d_all$user_id)
tr1d_all$user_id <- as.factor(tr1d_all$user_id)
tr9d_all$hero_id <- as.factor(tr9d_all$hero_id)
tr1d_all$hero_id <- as.factor(tr1d_all$hero_id)
ts9d_all$user_id <- as.factor(ts9d_all$user_id)
ts1d_all$user_id <- as.factor(ts1d_all$user_id)
ts9d_all$hero_id <- as.factor(ts9d_all$hero_id)
ts1d_all$hero_id <- as.factor(ts1d_all$hero_id)
str(tr9d_all)
str(tr1d_all)
str(ts9d_all)
str(ts1d_all)
################################ Tuning of GBM for best model################################
set.seed(1)
gbm_model <- gbm(formula = kda_ratio ~ .,
distribution = "gaussian",
data = ts9d_all,
n.trees = 8000,
cv.folds = 5)
# Optimal ntree estimate based on CV
ntree_opt_cv <- gbm.perf(object = gbm_model,
method = "cv")
print(paste0("Optimal n.trees (CV Estimate): ", ntree_opt_cv))
# Generate predictions on the test set using ntree_opt_cv number of trees
gbm_predictions <- predict(object = gbm_model,
newdata = ts1d_all,
n.trees = ntree_opt_cv)
write.csv(gbm_predictions, "gbm_predictions.csv")
gbm_model <- gbm(formula = kda_ratio ~ .,
distribution = "gaussian",
data = tr9d_all,
n.trees = 8000,
cv.folds = 5)
gbm_model <- gbm(formula = kda_ratio ~ .,
distribution = "gaussian",
data = ts9d_all,
n.trees = 8000,
cv.folds = 5)
help("gbm")
# Optimal ntree estimate based on CV
ntree_opt_cv <- gbm.perf(object = gbm_model,
method = "cv")
print(paste0("Optimal n.trees (CV Estimate): ", ntree_opt_cv))
# Generate predictions on the test set using ntree_opt_cv number of trees
gbm_predictions <- predict(object = gbm_model,
newdata = ts1d_all,
n.trees = ntree_opt_cv)
head(gbm_predictions)
